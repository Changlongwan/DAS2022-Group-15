---
title: "project2"
author: "Lixia"
date: "2022/3/21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE}
library(kableExtra)
library(gridExtra)
library(tinytex)
library(equatiomatic)
library(gapminder)
library(ggplot2)
library(dplyr)
library(moderndive)
library(ISLR)
library(skimr)
library(plotly)
library(tidyr)
library(jtools)
library(janitor)
library(infer)
library(broom)
library(tidyverse)
library(sjPlot)
library(stats)

```


```{r}
dataset<-read.csv("dataset15.csv")
head(dataset)
```


```{r}
dataset$price <- cut(dataset$price, breaks = c(0,1000,100000), labels =c("low","high"), include.lowest = TRUE)
head(dataset)
```


```{r}
data1 <- dataset %>%
                  dplyr::select(price, sellable_online)
head(data1)
```

```{r}
data1 %>% 
  tabyl(price, sellable_online) %>% 
  adorn_percentages() %>% 
  adorn_pct_formatting() %>% 
  adorn_ns() # To show original counts

```
```{r}
ggplot(data1, aes(x=sellable_online ,  y = ..prop.., group=price, fill=price)) + 
    geom_bar(position="dodge", stat="count") +
    labs(y = "Proportion",title = "Barplot of price by sellable_online.")
```

We can see that a larger proportion of instructors in the low price group are true sellable online (1.5% vs 98.5%), the high price group is also comprised of more true sellable online (00.0% vs 100.0%). Now we shall fit a logistic regression model to determine whether the classification of price can be predicted from sellable online.

#Log-odds
The logistic regression model is given by:
```{r}
model.sellable <- glm(price ~ sellable_online , data = data1, family = binomial(link = "logit"))
equatiomatic::extract_eq(model.sellable)
```
Again, the baseline category for our binary response is high price. Also, the baseline category for our explanatory variable is False sellable online.


```{r}
equatiomatic::extract_eq(model.sellable,use_coefs = TRUE)
```
Hence, the log-odds of the price being high increase by 14.9 if they are in the true sellable online group. This provides us with a point estimate of how the log-odds changes with sellable_online, however, we are also interested in producing a 95% confidence interval for these log-odds. This can be done using the confint function in the MASS package:

```{r}
```

```{r}
mod.sellable.coef.logodds <- model.sellable %>%
                            summary() %>%
                            coef()
mod.sellable.coef.logodds
```

```{r}
sellable.logodds.lower <- mod.sellable.coef.logodds["sellable_onlineTRUE", "Estimate"] - 
                        1.96 * mod.sellable.coef.logodds["sellable_onlineTRUE", "Std. Error"]
sellable.logodds.lower
```

```{r}
sellable.logodds.upper <- mod.sellable.coef.logodds["sellable_onlineTRUE", "Estimate"] + 
                        1.96 * mod.sellable.coef.logodds["sellable_onlineTRUE", "Std. Error"]
sellable.logodds.upper
```

Hence the point estimate for the log-odds is 14.9, which has a corresponding 95% confidence interval of (-1260.812, 1290.612). This can be displayed graphically using the plot_model function from the sjPlot package by simply passing our model as an argument:

```{r}
plot_model(model.sellable, show.values = TRUE, transform = NULL,
           title = "Log-Odds (High Price)", show.p = FALSE)
```

Now, let’s add the estimates of the log-odds to our data set:
```{r}
datanew <- data1 %>%
                  mutate(logodds.high = predict(model.sellable))
head(datanew)
```

#Odds

##partA (maybe wrong)
On the odds scale the regression coefficients are given by
```{r}
model.sellable %>%
 coef() %>%
  exp()
```

The (Intercept) gives us the odds of the price being high given that they are in the False sellable_online group, that is, 1.736771e-07  (the indicator function is zero in that case). The odds of the price being high given they are in the True sellable_online group are 2.958142e+06 times greater than the odds if they were in the False sellable_online group.

```{r}
# the number of sellable_onlineTRUE
psellable_onlineTRUE <- datanew %>%
              filter(sellable_online == "TRUE") %>%
              summarize(n()) %>%
              pull()

# the number of high price in sellable_onlineFALSE
psellable_onlineFALSE.high <- datanew %>%
              filter(sellable_online == "FALSE", price == "high") %>%
              summarize(n()) %>%
              pull()

# the proportion/probability of high in the sellable_onlineFALSE
prob.sellable_onlineFALSE.high <- psellable_onlineFALSE.high / psellable_onlineTRUE
odds.sellable_onlineFALSE.high <- prob.sellable_onlineFALSE.high / (1 - prob.sellable_onlineFALSE.high)
odds.sellable_onlineFALSE.high
```

#partB

Now, let’s add the estimates of the odds to our data set:
```{r}
datanew2 <- datanew %>%
                  mutate(odds.high = exp(logodds.high))
head(datanew2)
```

#Probabilities

Let’s add the probabilities to our data:

```{r}
datanew3 <- datanew2 %>%
                  mutate(probs.high = fitted(model.sellable))
head(datanew3)
```

Finally, we can use the plot_model() function from the sjPlot package to produce the estimated probabilities by sellable_online as follows:

#code error
```{r}

```




# one numerical explanatory variable of height

```{r}
dataA<-read.csv("dataset15.csv")
head(dataA)
```


```{r}
dataA=dataA %>%
  dplyr::select(price,height)
```

# delete NA value
```{r}
dataheight=dataA %>% na.omit(dataA$height)
dataheight$price <- cut(dataheight$price, breaks = c(0,1000,100000), labels =c("low","high"), include.lowest = TRUE)
head(dataheight)
```

Now, let’s look at a boxplot of height by price to get an initial impression of the data:
```{r}
ggplot(data = dataheight, aes(x = price, y = height, fill = price)) +
  geom_boxplot() +
  labs(x = "price", y = "height")+ 
  theme(legend.position = "none")

```

Here we can see that the high price tend to be more height than that of low price. Now, let’s fit a logistic regression model to see whether height is a significant predictor of the odds of the price being high or low.


# Log-odds

```{r}
model.height <- glm(price ~ height, data = dataheight, 
             family = binomial(link = "logit"))
```


```{r}
model.height %>%
  summary()
```


```{r}
summ(model.height)
```


```{r}
equatiomatic::extract_eq(model.height,use_coefs = TRUE)
```

where p=Prob(high) and 1−p=Prob(low). Hence, the log-odds of the instructor being high price increase by 0.01 for every one unit increase in height. This provides us with a point estimate of how the log-odds changes with height, however, we are also interested in producing a 95% confidence interval for these log-odds. This can be done using the confint function in the MASS package:


```{r}
confint(model.height)
```
Hence the point estimate for the log-odds is 0.01, which has a corresponding 95% confidence interval of (0.009416632, 0.01757485). This can be displayed graphically using the plot_model function from the sjPlot package by simply passing our model as an argument:

```{r}
plot_model(model.height, show.values = TRUE, transform = NULL,
           title = "Log-Odds (High price)", show.p = FALSE)
```


```{r}
datanew <- dataheight %>%
                  mutate(logodds.high = predict(model.height))
head(datanew)
```

```{r}
datanew2 <- datanew %>%
                  mutate(odds.high = exp(logodds.high))
head(datanew2)
```


```{r}
datanew3 <- datanew2 %>%
                  mutate(probs.high = fitted(model.height))
head(datanew3)
```


```{r}
```

